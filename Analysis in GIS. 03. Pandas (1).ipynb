{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Pandas</b> is a key package in Python that allows us to read, write, manipulate, group, and visualize tabular data.  It comes pre-installed with both Anaconda and the ArcGIS Python packages.  We typically load it in as \"pd\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the federal_elections_2016.csv file from the course website, and make sure it's in the same directory that you downloaded this notebook into.\n",
    "\n",
    "We load our data by using the method \"read_csv\" which is a part of Pandas (\"pd\").  We'll load it into a variable called \"df\" for \"data frame\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('federal_elections_2016.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It's very easy to summarize datasets this way, as well:\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or we can ask for specific fields\n",
    "\n",
    "df['electoral_votes_trump'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It's easy to calculate fields in Pandas:\n",
    "\n",
    "df['prc_trump'] = 100 * df['popular_votes_trump'] / df['total_votes']\n",
    "df['prc_clinton'] = 100* df['popular_votes_clinton'] / df['total_votes']\n",
    "\n",
    "df['prc_trump'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# But dtaa si msesy..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a quick introduction, that went pretty smoothly.  But badly formatted data can throw a wrench into the works.  \n",
    "\n",
    "As a Data Scientist, cleaning data is all part of the job."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Excel Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to repeat that, but with an actual Excel file...\n",
    "\n",
    "First, we load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('federalelections2016.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That should work, but what did we get?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we see here isn't our data, it's a look at the organization of the worksheets in the Excel document. Or dataset had many worksheets, so we need to tell Pandas which one we want.  Put your cursor on \"read_excel\" and hit \"Shift-Tab\" to bring up tool tips.  Can you guess which one is necessary to specify which sheet we want to use?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('federalelections2016.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can specify the number of the sheet (from left, starting with 0) or you can specify the name, but be precise!  Any typo will throw an error, including a capitalization error.  On the other hand, specifying the name is a bit safer, as if the worksheets shift order, it will still be correctly located.\n",
    "\n",
    "We might do a read like this...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('federalelections2016.xlsx',sheet_name='Table 2. Electoral &  Pop Vote')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But this didn't quite work either.  Remember, we have <b>extra lines</b> at the top of our spreadsheet, so we need to skip those rows when we read it in.  Fortunately, this is easy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('federalelections2016.xlsx',sheet_name='Table 2. Electoral &  Pop Vote',skiprows=3)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a bit better, but since the variable names were split on different rows, Pandas is having a hard time. :( This isn't really Pandas fault: this is not a well formatted dataset, but that's not unusual!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open your dataset in Excel, and change your column names to:\n",
    "\n",
    "state, electoral_votes_trump, electoral_votes_clinton, popular_votes_trump, popular_votes_clinton, popular_votes_other, total_votes.  Save the file, and then open it again.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('federalelections2016.xlsx',sheet_name='Table 2. Electoral &  Pop Vote',skiprows=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fisher's Iris Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('fisher.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can plot a scatterplot easily with pandas (or matplotlib)\n",
    "\n",
    "df.plot.scatter(x='petal_width',y='petal_length')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or make a histogram\n",
    "\n",
    "df['sepal_width'].plot.hist(bins=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or group data, and provide statistics\n",
    "\n",
    "grp = df.groupby('species')\n",
    "grp.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
